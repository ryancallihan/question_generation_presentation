% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Baayan2015,
	Title                    = {Abstraction, storage and naive disciminative learning},
	Author                   = {Harald Baayan and Michael Ramscar},
	Year                     = {2015},
	
	Abstract                 = {The English sentence you want milk can be uttered in a variety of circumstances, such as a mother
	about to feed her baby (answer: bweeeh), a father asking a toddler whether she would like a glass
	of milk (answer: yes please), or an air hostess serving black tea in economy class (answer: sure).
	Furthermore, similar sentences (you want coffee, you want water, would you like coffee, would you
	like a cup of coffee) are also produced and understood in a wide variety of contexts. What are the
	cognitive principles that allow us to produce and understand many different sentences across an
	even greater kaleidoscope of contexts and situations?
	In this chapter, we discuss three very different approaches that seek to answer this fundamental
	question about how language works. We begin with the oldest one, the structuralist tradition and
	its formalist offshoots, which posits that rules obtained by a process of abstraction are essential to
	understanding language. The second approach argues that generalizations are achieved not through
	abstraction, but by analogical reasoning over large numbers of instances of language use stored in
	memory. The third approach takes the perspective that to understand language and productivity
	in language, it is essential to take into account well-established basic principles of discrimination
	learning.},
	File                     = {:W16PhoneticsR/Reading/Baayen_2015_abstraction_ndl.pdf:PDF},
	Keywords                 = {rules, schemata, exemplars, analogy, hybrid models, discrimination learning},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Bickerton2007,
	Title                    = {Language evolution: A brief guide for linguists},
	Author                   = {Derek Bickerton},
	Journal                  = {Lingua},
	Year                     = {2007},
	
	Abstract                 = {For the benefit of linguists new to the field of language evolution, the author sets out the issues that need
	to be distinguished in any research on it. He offers a guided tour of contemporary approaches, including the
	work of linguists (Bickerton, Carstairs-McCarthy, Chomsky, Hurford, Jackendoff, Pinker, Wray), animal
	behaviour experts (Dunbar, Hauser, Premack, Savage-Rumbaugh), neurophysiologists (Arbib, Calvin),
	psychologists (Corballis, Donald), archaeologists (Davidson), and computer modellers (Batali, Kirby,
	Steels). He criticises the expectation that recent discoveries such as ‘mirror neurons’ and the FOXP2 gene
	will provide easy answers. He emphasises the extremely interdisciplinary nature of this field, and also the
	importance of involvement in it by linguists, after more than a century of neglect.},
	File                     = {:/home/ryanc/Grive/School/W16MOLE/Bickerton(2007)langauge_evolution_a_brief_guide_for_linguists.pdf:PDF},
	Keywords                 = {language evolution protolanguage holophrastic},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.10}
}

@PhdThesis{Bok2013,
	Title                    = {Analyzing connectivity:
	A proposition for a better model of analysis
	for connective occurrence in texts},
	Author                   = {Felice Bok},
	School                   = {Tillburg University},
	Year                     = {2013},
	
	Owner                    = {ryanc},
	Timestamp                = {2016.12.13}
}

@Article{Crossley2007,
	Title                    = {A linguistic analysis of simplified and authentic texts},
	Author                   = {Crossley, Scott A and Louwerse, Max M and McCarthy, Philip M and McNamara, Danielle S},
	Journal                  = {The Modern Language Journal},
	Year                     = {2007},
	Number                   = {1},
	Pages                    = {15--30},
	Volume                   = {91},
	
	Publisher                = {Wiley Online Library}
}

@Article{DuBay2004,
	Title                    = {The Principles of Readability.},
	Author                   = {DuBay, William H},
	Journal                  = {Online Submission},
	Year                     = {2004},
	
	File                     = {:W16Complexity/DuBay2004PrinciplesofReadability.pdf:PDF},
	Publisher                = {ERIC}
}

@Article{EmilyPitler2008,
	Title                    = {Easily identifiable discourse relations},
	Author                   = {Emily Pitler, Mridhula Raghupathy, Hena Mehta, et al.},
	Year                     = {2008},
	
	Owner                    = {ryanc},
	Timestamp                = {2016.12.13}
}

@Article{GraesserEtAl2011,
	Title                    = {Computational Analyses of Multilevel Discourse Comprehension},
	Author                   = {Graesser, Arthur C. and McNamara, Danielle S.},
	Journal                  = {Topics in Cognitive Science},
	Year                     = {2011},
	Number                   = {2},
	Pages                    = {371--398},
	Volume                   = {3},
	
	Doi                      = {10.1111/j.1756-8765.2010.01081.x},
	ISSN                     = {1756-8765},
	Keywords                 = {Discourse processes, Text comprehension, Coherence, Cohesion, Semantics, Computational linguistics},
	Publisher                = {Blackwell Publishing Ltd},
	Url                      = {http://dx.doi.org/10.1111/j.1756-8765.2010.01081.x}
}

@Article{Graesser2004,
	Title                    = {Coh-Metrix: Analysis of text on cohesion and language},
	Author                   = {Graesser, Arthur C.
	and McNamara, Danielle S.
	and Louwerse, Max M.
	and Cai, Zhiqiang},
	Journal                  = {Behavior Research Methods, Instruments, {\&} Computers},
	Year                     = {2004},
	Number                   = {2},
	Pages                    = {193--202},
	Volume                   = {36},
	
	Abstract                 = {Advances in computational linguistics and discourse processing have made it possible to automate many language- and text-processing mechanisms. We have developed a computer tool called Coh-Metrix, which analyzes texts on over 200 measures of cohesion, language, and readability. Its modules use lexicons, part-of-speech classifiers, syntactic parsers, templates, corpora, latent semantic analysis, and other components that are widely used in computational linguistics. After the user enters an English text, Coh-Metrix returns measures requested by the user. In addition, a facility allows the user to store the results of these analyses in data files (such as Text, Excel, and SPSS). Standard text readability formulas scale texts on difficulty by relying on word length and sentence length, whereas Coh-Metrix is sensitive to cohesion relations, world knowledge, and language and discourse characteristics.},
	Doi                      = {10.3758/BF03195564},
	ISSN                     = {1532-5970},
	Owner                    = {ryanc},
	Timestamp                = {2016.12.13},
	Url                      = {http://dx.doi.org/10.3758/BF03195564}
}

@Book{Halliday1976,
	Title                    = {Cohesion in English},
	Author                   = {Halliday, M. A. K., and Ruqaiya Hasan},
	Publisher                = {London: Longman},
	Year                     = {1976}
}

@Misc{penntreebank,
	Title                    = {Penn Discourse Treebank},
	
	Author                   = {https://www.seas.upenn.edu/~pdtb/},
	
	Owner                    = {ryanc},
	Timestamp                = {2016.12.14}
}

@Article{Hym2005,
	Title                    = {Word-Prosodic Typology},
	Author                   = {Larry M. Hyman},
	Journal                  = {UC Berkeley Phonology Lab Annual},
	Year                     = {2005},
	
	File                     = {:W16Typology/hyman_2006.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Jackendoff1999,
	Title                    = {Possible stages in the evolution of the language capacity},
	Author                   = {Ray Jackendoff},
	Journal                  = {Trends in Cognitive Sciences},
	Year                     = {1999},
	
	Month                    = {July},
	Number                   = {7},
	Pages                    = {272-279},
	Volume                   = {3},
	
	Abstract                 = {Much current discussion of the evolution of language has concerned the emergence of
	a stage in which single vocal or gestural signals were used symbolically. Assuming the
	existence of such a stage, the present review decomposes the emergence of modern
	language into nine partially ordered steps, each of which contributes to precision and
	variety of expression. Bickerton’s proposed ‘protolanguage’ falls somewhere in the
	middle of this succession. In addition to the by-now accepted evidence from language
	learning, language disorders, and ape language experiments, modern languages
	provide evidence of these stages of evolution through the presence of detectable
	‘fossils’ in vocabulary and grammar.},
	File                     = {:/home/ryanc/Grive/School/W16MOLE/Jackendoff(1999)_possible_stages_in_the_evolution_of_the_language_capacity.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.10}
}

@Book{Jurafsky1999,
	Title                    = {Speech and Language Processing},
	Author                   = {Daniel Jurafsky and James H. Martin},
	Publisher                = {Pretice Hall},
	Year                     = {1999},
	
	File                     = {:Textbooks/Speech and Language Processing_Jurafsky_Martin_2009.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Kirby2007,
	Title                    = {The Evolution of Language},
	Author                   = {Simon Kirby},
	Journal                  = {Oxford Handbook of Evolutionary Psychology},
	Year                     = {2007},
	Pages                    = {669-681},
	
	File                     = {:/home/ryanc/Grive/School/W16MOLE/Kirby(2007)_the_evolution_of_language.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.10}
}

@Article{Louwerse2001,
	Title                    = {An analytic and cognitive parameterization of coherence relations},
	Author                   = {Louwerse, Max},
	Journal                  = {Cognitive Linguistics},
	Year                     = {2001},
	Number                   = {3},
	Pages                    = {291-315},
	Volume                   = {12}
}

@Book{McNamara2014,
	Title                    = {Automated evaluation of text and discourse with Coh-Metrix},
	Author                   = {McNamara, {Danielle S.} and Graesser, {Arthur C.} and McCarthy, {Philip M.} and Zhiqiang Cai},
	Publisher                = {Cambridge University Press},
	Year                     = {2014},
	
	Doi                      = {10.1017/CBO9780511894664},
	ISBN                     = {9780521137294}
}

@Article{CM,
	Title                    = {Coh-Metrix},
	Author                   = {McNamara, D.S., Louwerse, M.M., Cai, Z., \& Graesser, A.},
	Year                     = {2005},
	
	Month                    = {January},
	Note                     = {Retrieved 1.4.2017},
	Volume                   = {version 1.4},
	
	Url                      = {http://www.cohmetrix.com}
}

@Electronic{CohMetrix,
	Title                    = {Coh-Metrix},
	Author                   = {McNamara, D.S., Louwerse, M.M., Cai, Z., \& Graesser, A.},
	HowPublished             = {Coh-Metrix version 1.4},
	Month                    = {January},
	Url                      = {from http//:cohmetrix.memphis.edu},
	Year                     = {2005},
	
	Timestamp                = {01.04.2017}
}

@Article{Meurers2012,
	Title                    = {Natural Language Processing and Language Learning},
	Author                   = {Detmar Meurers},
	Journal                  = {Encyclopedia of Applied Linguistics},
	Year                     = {2012},
	
	Abstract                 = {As a relatively young field of research and development started by work on cryptanalysis and
	machine translation around 50 years ago, Natural Language Processing (NLP) is concerned
	with the automated processing of human language. It addresses the analysis and generation
	of written and spoken language, though speech processing is often regarded as a separate
	subfield. NLP emphasizes processing and applications and as such can be seen as the applied
	side of Computational Linguistics, the interdisciplinary field of research concerned with for-
	mal analysis and modeling of language and its applications at the intersection of Linguistics,
	Computer Science, and Psychology. In terms of the language aspects dealt with in NLP,
	traditionally lexical, morphological and syntactic aspects of language were at the center of
	attention, but aspects of meaning, discourse, and the relation to the extra-linguistic context
	have become increasingly prominent in the last decade. A good introduction and overview
	of the field is provided in Jurafsky & Martin (2009).
	This article explores the relevance and uses of NLP in the context of language learning,
	focusing on written language. As a concise characterization of this emergent subfield, the
	discussion will focus on motivating the relevance, characterizing the techniques, and delin-
	eating the uses of NLP; more historical background and discussion can be found in Nerbonne
	(2003) and Heift & Schulze (2007).
	One can distinguish two broad uses of NLP in this context: On the one hand, NLP can be used
	to analyze learner language, i.e., words, sentences, or texts produced by language learners.
	This includes the development of NLP techniques for the analysis of learner language by
	tutoring systems in Intelligent Computer-Assisted Language Learning (ICALL, cf. Heift,
	this volume), automated scoring in language testing, as well as the analysis and annotation
	of learner corpora (cf. Granger, this volume).
	On the other hand, NLP for the analysis of native language can also play an important role
	in the language learning context. Applications in this second domain support the search for
	and the enhanced presentation of native language reading material for language learners, they
	provide targeted access to relevant examples from native language corpora, or they support
	the generation of exercises, games, and tests based on native language materials.},
	File                     = {:Textbooks/Natural Language Processing and Language Learning_Meurers_2012.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Nivre2016,
	Title                    = {Universal Dependencies v1: A Multilingual Treebank Collection},
	Author                   = {Joakim Nivre and Marie-Catherine de Marneffe and Filip Ginter and Yoav Goldberg and Jan Hajic and Christopher D. Manning and Ryan McDonald and Slav Petrov and Sampo Pyysalo and Natalia Silveira and Reut Tsarfaty and Daniel Zeman},
	Journal                  = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)},
	Year                     = {2016},
	
	Month                    = {May}
}

@Book{Ortega2014,
	Title                    = {Understanding second language acquisition},
	Author                   = {Ortega, Lourdes},
	Publisher                = {Routledge},
	Year                     = {2014},
	
	File                     = {:W16SLA/Understanding Second Language Acquisiton_ Ortega 2009.pdf:PDF}
}

@Article{PInker1990,
	Title                    = {Natural language and natural selection},
	Author                   = {Steven PInker and Paul Bloom},
	Journal                  = {Behavioral and Brain Sciences},
	Year                     = {1990},
	Pages                    = {707-784},
	Volume                   = {13},
	
	Abstract                 = {Abstract: Many people have argued that the evolution of the human language faculty cannot be explained by Darwinian natural
	selection. Chomsky and Gould have suggested that language may have evolved as the by-product of selection for other abilities or as a
	consequence of as-yet unknown laws of growth and fonn. Others have argued that a biologic;al specialization for grammar is
	incompatible with every tenet of Darwinian theory - that it shows no genetic variation, could not exist in any intennediate fonns,
	confers no selective advantage, and would require more evolutionary time and genomic space than is available. We examine these
	arguments and show that they depend on inaccurate assumptions about biology or language or both. Evolutionary theory offers clear
	criteria for when a trait should be attributed to natural selection: complex design for some function, and the absence of alternative
	processes capable of explaining such complexity. Human language meets these criteria: Grammar is a complex mechanism tailored to
	the transmission of propositional structures through a serial interface. Autonomous and arbitrary grammatical phenomena have been
	offered as counterexamples to the position that language is an adaptation, but this reasoning is unsound: Communication prot0c6ls
	depend on arbitrary conventions that are adaptive as long as they are shared. Consequently, language acquisition in the child should
	systematically differ from language evolution in the species, and attempts to analogize them are misleading. Reviewing other
	arguments and data, we conclude that there is every reason to believe that a specialization for grammar evolved by a conventional
	neo-Darwinian process},
	File                     = {:/home/ryanc/Grive/School/W16MOLE/PinkerBloom(1990)_natural_language_and_natural_selection.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.10}
}

@Article{Pitler2008,
	Title                    = {Revisiting readability: A unified framework for predicting text quality},
	Author                   = {Pitler, Emily and Nenkova, Ani},
	Year                     = {2008},
	Pages                    = {186--195},
	
	Booktitle                = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
	Organization             = {Association for Computational Linguistics}
}

@Article{Prasadea2008,
	Title                    = {The Penn Discourse TreeBank 2.0},
	Author                   = {Prasad, Rashmi and Dinesh, Nikhil and Lee, Alan and Miltsakaki, Eleni and Robaldo, Livio and Ioshi, Aravind and Webber, Bonnie},
	Year                     = {2008}
}

@Manual{PDTBMan,
	Title                    = {The Penn Discourse Treebank 2.0 Annotation Manual},
	Author                   = {Prasad, Rashmi and Dinesh, Nikhil and Lee, Alan and Miltsakaki, Eleni and Robaldo, Livio and Ioshi, Aravind and Webber, Bonnie},
	Year                     = {2007}
}

@Article{Rosenbach2008,
	Title                    = {Language change as cultural evolution: Evolutionary approaches to language change},
	Author                   = {Anette Rosenbach},
	Year                     = {2008},
	
	File                     = {:/home/ryanc/Grive/School/W16MOLE/Rosenbach(2008)_language_change_as_cultural_evolution.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.10}
}

@Book{Sadler1994,
	Title                    = {MachineTranslation: an Introductory Guide},
	Author                   = {Douglas Arnold
	Lorna Balkan 
	Siety Meijer 
	R. Lee Humphreys
	Louisa Sadler},
	Publisher                = {NCC Blackwell Ltd.},
	Year                     = {1994},
	
	File                     = {:Textbooks/Machine Translation An Introductory Guide_Arnold_Douglas_1996.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{ScottA.Crossley2007,
	Title                    = {A Linguistic Analysis of Simplified and Authentic Texts},
	Author                   = {Scott A. Crossley, Max M. Louwerse, Philip M. McCarthy and Danielle S. McNamara},
	Journal                  = {The Modern Language Journal},
	Year                     = {2007},
	Number                   = {1},
	Pages                    = {15-30},
	Volume                   = {91}
}

@Article{Vajjala2014,
	Title                    = {Exploring Measures of "Readability" for Spoken Language: Analyzing Linguistic features of subtitles to identify age-specific TV programs},
	Author                   = {Sowmya Vajjala and Detmar Meurers},
	Journal                  = {Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations},
	Year                     = {2014},
	
	Month                    = {April},
	Pages                    = {21-29},
	
	Abstract                 = {We investigate whether measures of read-
	ability can be used to identify age-specific
	TV programs. Based on a corpus of BBC
	TV subtitles, we employ a range of lin-
	guistic readability features motivated by
	Second Language Acquisition and Psy-
	cholinguistics research.
	Our hypothesis that such readability fea-
	tures can successfully distinguish between
	spoken language targeting different age
	groups is fully confirmed. The classifiers
	we trained on the basis of these readability
	features achieve a classification accuracy
	of 95.9%. Investigating several feature
	subsets, we show that the authentic mate-
	rial targeting specific age groups exhibits
	a broad range of linguistics and psycholin-
	guistic characteristics that are indicative of
	the complexity of the language used.},
	File                     = {:W16Complexity/Reading/Vajjala.Meurers-14a.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Vajjala2014a,
	Title                    = {Readability assessment for text simplification},
	Author                   = {Sowmya Vajjala and Detmar Meurers},
	Journal                  = {International Journal of Applied Linguistics},
	Year                     = {2014},
	Number                   = {2},
	Pages                    = {194-222},
	Volume                   = {165},
	
	Abstract                 = {Readability assessment can play a role in the evaluation of a simplification algo-
	rithm as well as in the identification of what to simplify. While some previous
	research used traditional readability formulas to evaluate text simplification,
	there is little research into the utility of readability assessment for identifying and
	analyzing sentence level targets for text simplification. We explore this aspect in
	our paper by first constructing a readability model that is generalizable across
	corpora and across genres and later adapting this model to make sentence-level
	readability judgments.
	
	First, we report on experiments establishing that the readability model inte-
	grating a broad range of linguistic features works well at a document level, per-
	forming on par with the best systems on a standard test corpus. Next, the model
	is confirmed to be transferable to different text genres. Moving from documents
	to sentences, we investigate the model’s ability to correctly identify the difference
	in reading level between a sentence and its human simplified version. We con-
	clude that readability models can be useful for identifying simplification targets
	for human writers and for evaluating machine generated simplifications.},
	File                     = {:W16Complexity/Reading/Vajjala.Meurers-14b.pdf:PDF},
	Keywords                 = {generalizability of readability models, readability assessment,
	sentence readability, simplification evaluation, text simplification},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Vajjala2013,
	Title                    = {On The Applicability of Readability Models to Web Texts},
	Author                   = {Sowmya Vajjala and Detmar Meurers},
	Journal                  = {Proceedings of the 2nd Workshop on Predicting and Improving Text Readability for Target Reader Populations},
	Year                     = {2013},
	
	Month                    = {August},
	Pages                    = {59-68},
	
	Abstract                 = {An increasing range of features is being
	used for automatic readability classifica-
	tion. The impact of the features typically
	is evaluated using reference corpora con-
	taining graded reading material. But how
	do the readability models and the features
	they are based on perform on real-world
	web texts? In this paper, we want to take a
	step towards understanding this aspect on
	the basis of a broad range of lexical and
	syntactic features and several web datasets
	we collected.
	Applying our models to web search re-
	sults, we find that the average reading level
	of the retrieved web documents is rela-
	tively high. At the same time, documents
	at a wide range of reading levels are iden-
	tified and even among the Top-10 search
	results one finds documents at the lower
	levels, supporting the potential usefulness
	of readability ranking for the web. Finally,
	we report on generalization experiments
	showing that the features we used gener-
	alize well across different web sources.},
	File                     = {:W16Complexity/Reading/Vajjala.Meurers-13.pdf:PDF},
	Keywords                 = {readability weebit},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{Vajjala2012,
	Title                    = {On Improving the Accuracy of Readability Classification using Insights from Second Language Acquisition},
	Author                   = {Sowmya Vajjala and Detmar Meurers},
	Journal                  = {The 7th Workshop on the Innovative Use of NLP for Building Educational Applications},
	Year                     = {2012},
	
	Month                    = {June},
	Pages                    = {163-173},
	
	Abstract                 = {We investigate the problem of readability as-
	sessment using a range of lexical and syntac-
	tic features and study their impact on predict-
	ing the grade level of texts. As empirical ba-
	sis, we combined two web-based text sources,
	Weekly Reader and BBC Bitesize, targeting
	different age groups, to cover a broad range
	of school grades. On the conceptual side, we
	explore the use of lexical and syntactic mea-
	sures originally designed to measure language
	development in the production of second lan-
	guage learners. We show that the develop-
	mental measures from Second Language Ac-
	quisition (SLA) research when combined with
	traditional readability features such as word
	length and sentence length provide a good
	indication of text readability across different
	grades. The resulting classifiers significantly
	outperform the previous approaches on read-
	ability classification, reaching a classification
	accuracy of 93.3%.},
	File                     = {:W16Complexity/Reading/Vajjala.Meurers-12.pdf:PDF},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}

@Article{VanderHulst2011,
	Title                    = {Pitch accent systems},
	Author                   = {Van der Hulst, Harry},
	Journal                  = {The Blackwell companion to phonology},
	Year                     = {2011},
	Pages                    = {1003--1026},
	Volume                   = {2},
	
	File                     = {:W16Typology/hulst_2011_Pitch_Accent_Systems.pdf:PDF}
}

@Book{Velupillai2012,
	Title                    = {An Introduction to Linguistic Typology},
	Author                   = {Viveka Velupillai},
	Publisher                = {John Benjamins Publishing Company},
	Year                     = {2012},
	
	File                     = {:W16Typology/Velupillai_2012.pdf:PDF},
	Keywords                 = {typology linguistics},
	Owner                    = {ryanc},
	Timestamp                = {2016.11.11}
}


@misc{pdt3.0,
	author = {Eduard Bej{\v{c}}ek and Eva Haji{\v{c}}ov{\'{a}} and Jan Haji{\v{c}} and Pavl{\'{i}}na J{\'{i}}nov{\'{a}} and V{\'{a}}clava Kettnerov{\'{a}} and Veronika Kol{\'{a}}{\v{r}}ov{\'{a}} and Marie Mikulov{\'{a}} and Ji{\v{r}}{\'{i}} M{\'{i}}rovsk{\'{y}} and Anna Nedoluzhko and Jarmila Panevov{\'{a}} and Lucie Pol{\'{a}}kov{\'{a}} and Magda {\v{S}}ev{\v{c}}{\'{i}}kov{\'{a}} and Jan {\v{S}}t{\v{e}}p{\'{a}}nek and {\v{S}}{\'{a}}rka Zik{\'{a}}nov{\'{a}}},
	title = {Prague Dependency Treebank 3.0},
	date = {2013},
	organization = {Univerzita Karlova v Praze, {MFF}, {\'{U}}{FAL}},
	year = {2013}
}

@misc{pdtguide,
	author = {Jan Haji{\v{c}} and Eva Haji{\v{c}}ov{\'{a}} and Jaroslava Hlav{\'{a}}{\v{c}}ov{\'{a}} and Vaclav Klime{\v{s}} and Ji{\v{r}}{\'{i}} M{\'{i}}rovsky and Petr Pajas and Jan {\v{S}}t{\v{e}}p{\'{a}}nek and Barbora Vidov{\'{a}} Hladk{\'{a}} and Zden{\v{e}}k {\v{Z}}abokrtsk{\'{y}}},
	title = {Prague Dependency Treebank 2.0 Guide},
	date = {2013},
	organization = {Univerzita Karlova v Praze, {MFF}, {\'{U}}{FAL}},
	year = {2013},
}

@misc{pdtannotation-a,
	author = {Jan Haji{\v{c}} and Jarmila Panevov\'{a} and Eva Bur\'{a}\v{n}ov\'{a} and Zde\v{n}ek Ure\v{s}ov\'{a} and Alla B\'{e}mov\'{a} },
	title = {ANNOTATIONS AT ANALYTICAL LEVEL},
	organization = {Univerzita Karlova v Praze, {MFF}, {\'{U}}{FAL}},
	year = {1999},
}

@misc{pdtannotation-t,
	author = {Marie Mikulov\'{a} and Allevtina B\'{e}mov\'{a} and Jan Haji{\v{c}} and Eva Haji{\v{c}}ov{\'{a}} and Ji\v{r}\'{i} Havelka and Veronika Kol\'{a}\v{r}ov\'{a} and Lucie Ku\v{c}ov\'{a} and Mark\'{e}ta Lopatkov\'{a} and Petr Pajas and Jarmila Panevov\'{a} and Magda Raz\'{i}mov\'{a} and Petr Sgall and Jan {\v{S}}t{\v{e}}p{\'{a}}nek and Zde\v{n}ek Ure\v{s}ov\'{a} and Kate\v{r}ina Vesel\'{a} and Zden{\v{e}}k {\v{Z}}abokrtsk{\'{y}} },
	title = {Annotation on the tectogrammatical
	layer in the Prague Dependency
	Treebank},
	organization = {Univerzita Karlova v Praze, {MFF}, {\'{U}}{FAL}},
	year = {1999},
}

@misc{pdtannotation-m,
	author = { Ji\v{r}\'{i} Hana and Daniel Zeman},
	title = {Manual for Morphological Annotation},
	organization = {Univerzita Karlova v Praze, {MFF}, {\'{U}}{FAL}},
	year = {1999},
}



@misc{Cmejrek2006,
	author = {Martin \v{C}mejrek},
	title = {Using Dependency Tree Structure for Czech - English Machine Translation},
	type = {Doctoral Thesis},
	institution = {Institute of Formal and Applied Linguistics Faculty of Mathematics and Physics Charles University},
	year = {2006},
}

@misc{Tiedemann2017,
	author = {J\"{o}rg Tiedemann},
	title = {Cross-Lingual Dependency Parsing for Closely Related Languages },
	journaltitle = {VarDial 2017},
	year = {2017},
}

@inproceedings{cmejrek2004,
	author    = {M. \v{C}mejrek  and   J. Cu\v{r}\'{i}n  and  J. Havelka},
	title     = {Prague Czech-English Dependency Treebank: Any Hopes for a Common Annotation Scheme?},
	booktitle = {HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation },
	editor = {A. Meyers},
	year      = 2004,
	month     = {May 2 - May 7},
	address   = {Boston, Massachusetts, USA},
	publisher = {Association for Computational Linguistics},
	pages     = {47--54}
}

@misc{hajic,
	author = {Jan Haji\v{c}},
	title = {The Prague
	Dependency Treebanks
	Morphology, Syntax, Semantics},
	year = {2010},
}

@inproceedings{Iyyer2014,
	Author = {Mohit Iyyer and Peter Enns and Jordan Boyd-Graber and Philip Resnik},
	Url = {docs/2014_acl_rnn_ideology.pdf},
	Booktitle = {Association for Computational Linguistics},
	Location = {Baltimore, MD},
	Year = {2014},
	Title = {Political Ideology Detection Using Recursive Neural Networks},
}


@Article{Dehghani2014,
	author = {Morteza Dehghani and Kenji Sagae and  Sonya Sachdeva and Jonathan Gratch},
	title = {Analyzing Political Rhetoric in Conservative and
	Liberal Weblogs Related to the Construction of the
	“Ground Zero Mosque”},
	journaltitle = {Journal of
	Information Technology & Politics},
	year = {2014},
	doi = {10.1080/19331681.2013.826613},
}

@article{graham2009,
	title={Liberals and conservatives rely on different sets of moral foundations.},
	author={Graham, Jesse and Haidt, Jonathan and Nosek, Brian A},
	journal={Journal of personality and social psychology},
	volume={96},
	number={5},
	pages={1029},
	year={2009},
	publisher={American Psychological Association}
}

@inproceedings{andrzejewski2011,
	title={A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic},
	author={Andrzejewski, David and Zhu, Xiaojin and Craven, Mark and Recht, Benjamin},
	booktitle={IJCAI Proceedings-International Joint Conference on Artificial Intelligence},
	volume={22},
	number={1},
	pages={1171},
	year={2011}
}

@article{joachims1999svmlight,
	title={Svmlight: Support vector machine},
	author={Joachims, Thorsten},
	journal={SVM-Light Support Vector Machine http://svmlight. joachims. org/, University of Dortmund},
	volume={19},
	number={4},
	year={1999}
}

@inproceedings{yano2009predicting,
	title={Predicting response to political blog posts with topic models},
	author={Yano, Tae and Cohen, William W and Smith, Noah A},
	booktitle={Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
	pages={477--485},
	year={2009},
	organization={Association for Computational Linguistics}
}

@article{pennebaker2001linguistic,
	title={Linguistic inquiry and word count: LIWC 2001},
	author={Pennebaker, James W and Francis, Martha E and Booth, Roger J},
	journal={Mahway: Lawrence Erlbaum Associates},
	volume={71},
	number={2001},
	pages={2001},
	year={2001}
}

@article{pennebaker2001linguistic,
	title={Linguistic inquiry and word count: LIWC 2001},
	author={Pennebaker, James W and Francis, Martha E and Booth, Roger J},
	journal={Mahway: Lawrence Erlbaum Associates},
	volume={71},
	number={2001},
	pages={2001},
	year={2001}
}

@article{tam2017,
	title={Classifying Reddit comments by subreddit},
	author={Tam, Jee Ian},
	year={2017}
}

@inproceedings{rehurek_lrec,
	title = {{Software Framework for Topic Modelling with Large Corpora}},
	author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
	booktitle = {{Proceedings of the LREC 2010 Workshop on New
	Challenges for NLP Frameworks}},
	pages = {45--50},
	year = 2010,
	month = May,
	day = 22,
	publisher = {ELRA},
	address = {Valletta, Malta},
	language={English}
}

@article{DBLP:journals/corr/abs-1301-3781,
	author    = {Tomas Mikolov and
	Kai Chen and
	Greg Corrado and
	Jeffrey Dean},
	title     = {Efficient Estimation of Word Representations in Vector Space},
	journal   = {CoRR},
	volume    = {abs/1301.3781},
	year      = {2013},
	url       = {http://arxiv.org/abs/1301.3781},
	archivePrefix = {arXiv},
	eprint    = {1301.3781},
	timestamp = {Wed, 07 Jun 2017 14:42:25 +0200},
	biburl    = {http://dblp.org/rec/bib/journals/corr/abs-1301-3781},
	bibsource = {dblp computer science bibliography, http://dblp.org}
}

@InProceedings{mostafazadeh-EtAl:2016:P16-1,
	author    = {Mostafazadeh, Nasrin  and  Misra, Ishan  and  Devlin, Jacob  and  Mitchell, Margaret  and  He, Xiaodong  and  Vanderwende, Lucy},
	title     = {Generating Natural Questions About an Image},
	booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	month     = {August},
	year      = {2016},
	address   = {Berlin, Germany},
	publisher = {Association for Computational Linguistics},
	pages     = {1802--1813},
	url       = {http://www.aclweb.org/anthology/P16-1170}
}
